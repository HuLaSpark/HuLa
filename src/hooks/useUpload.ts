import { createEventHook } from '@vueuse/core'
import apis from '@/services/apis'
import { UploadSceneEnum } from '@/enums'
import { fetch } from '@tauri-apps/plugin-http'
import { BaseDirectory, readFile } from '@tauri-apps/plugin-fs'
import { useConfigStore } from '@/stores/config'
import { Md5 } from 'digest-wasm'
import { useUserStore } from '@/stores/user'
import { getImageDimensions } from '@/utils/ImageUtils'
import { extractFileName, getMimeTypeFromExtension } from '@/utils/Formatting'

/** æ–‡ä»¶ä¿¡æ¯ç±»å‹ */
export type FileInfoType = {
  name: string
  type: string
  size: number
  suffix: string
  width?: number
  height?: number
  downloadUrl?: string
  second?: number
  thumbWidth?: number
  thumbHeight?: number
  thumbUrl?: string
}

/** ä¸Šä¼ æ–¹å¼ */
export enum UploadProviderEnum {
  /** é»˜è®¤ä¸Šä¼ æ–¹å¼ */
  DEFAULT = 'default',
  /** ä¸ƒç‰›äº‘ä¸Šä¼  */
  QINIU = 'qiniu'
}

/** ä¸Šä¼ é…ç½® */
export interface UploadOptions {
  /** ä¸Šä¼ æ–¹å¼ */
  provider?: UploadProviderEnum
  /** ä¸Šä¼ åœºæ™¯ */
  scene?: UploadSceneEnum
  /** æ˜¯å¦ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ ï¼ˆä»…å¯¹ä¸ƒç‰›äº‘æœ‰æ•ˆï¼‰ */
  useChunks?: boolean
  /** åˆ†ç‰‡å¤§å°ï¼ˆå•ä½ï¼šå­—èŠ‚ï¼Œé»˜è®¤4MBï¼‰ */
  chunkSize?: number
  /** æ˜¯å¦å¯ç”¨æ–‡ä»¶å»é‡ï¼ˆä½¿ç”¨æ–‡ä»¶å“ˆå¸Œä½œä¸ºæ–‡ä»¶åï¼‰ */
  enableDeduplication?: boolean
}

/** åˆ†ç‰‡ä¸Šä¼ è¿›åº¦ä¿¡æ¯ */
interface ChunkProgressInfo {
  uploadedChunks: number
  totalChunks: number
  currentChunkProgress: number
}

const Max = 100 // å•ä½M
const MAX_FILE_SIZE = Max * 1024 * 1024 // æœ€å¤§ä¸Šä¼ é™åˆ¶
const DEFAULT_CHUNK_SIZE = 4 * 1024 * 1024 // é»˜è®¤åˆ†ç‰‡å¤§å°ï¼š4MB
const QINIU_CHUNK_SIZE = 4 * 1024 * 1024 // ä¸ƒç‰›äº‘åˆ†ç‰‡å¤§å°ï¼š4MB
const CHUNK_THRESHOLD = 4 * 1024 * 1024 // 4MBï¼Œè¶…è¿‡æ­¤å¤§å°çš„æ–‡ä»¶å°†ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ 

/**
 * æ–‡ä»¶ä¸Šä¼ Hook
 */
export const useUpload = () => {
  // è·å–configStoreé…ç½®ä¸­çš„ossDomain
  const configStore = useConfigStore()
  const userStore = useUserStore()
  const isUploading = ref(false) // æ˜¯å¦æ­£åœ¨ä¸Šä¼ 
  const progress = ref(0) // è¿›åº¦
  const fileInfo = ref<FileInfoType | null>(null) // æ–‡ä»¶ä¿¡æ¯
  const currentProvider = ref<UploadProviderEnum>(UploadProviderEnum.DEFAULT) // å½“å‰ä¸Šä¼ æ–¹å¼

  const { on: onChange, trigger } = createEventHook()
  const onStart = createEventHook()

  /**
   * è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼
   * @param file æ–‡ä»¶
   * @returns MD5å“ˆå¸Œå€¼
   */
  const calculateFileHash = async (file: File): Promise<string> => {
    const startTime = performance.now()
    try {
      console.log('å¼€å§‹è®¡ç®—MD5å“ˆå¸Œå€¼ï¼Œæ–‡ä»¶å¤§å°:', file.size, 'bytes')
      const arrayBuffer = await file.arrayBuffer()
      // ä½¿ç”¨digest-wasmè®¡ç®—MD5
      const hash = await Md5.digest_u8(new Uint8Array(arrayBuffer))
      const endTime = performance.now()
      const duration = (endTime - startTime).toFixed(2)
      console.log(`MD5è®¡ç®—å®Œæˆï¼Œè€—æ—¶: ${duration}msï¼Œå“ˆå¸Œå€¼: ${hash}`)
      return hash
    } catch (error) {
      const endTime = performance.now()
      const duration = (endTime - startTime).toFixed(2)
      console.error(`è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼å¤±è´¥ï¼Œè€—æ—¶: ${duration}ms:`, error)
      // å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè¿”å›æ—¶é—´æˆ³ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
      return Date.now().toString()
    }
  }

  /**
   * æ ¹æ®æ–‡ä»¶åè·å–æ–‡ä»¶ç±»å‹
   * @param fileName æ–‡ä»¶å
   */
  const getFileType = (fileName: string): string => {
    const extension = fileName.split('.').pop()?.toLowerCase()

    // å¯¹äºå›¾ç‰‡ç±»å‹ï¼Œä½¿ç”¨ç»Ÿä¸€çš„ getMimeTypeFromExtension å‡½æ•°
    if (['jpg', 'jpeg', 'png', 'webp', 'gif', 'bmp', 'svg'].includes(extension || '')) {
      return getMimeTypeFromExtension(fileName)
    }

    // å…¶ä»–æ–‡ä»¶ç±»å‹
    switch (extension) {
      case 'mp4':
        return 'video/mp4'
      case 'mp3':
        return 'audio/mp3'
      default:
        return 'application/octet-stream' // é»˜è®¤ç±»å‹
    }
  }

  /**
   * ç”Ÿæˆæ–‡ä»¶å“ˆå¸Œ
   * @param options ä¸Šä¼ é…ç½®
   * @param fileObj æ–‡ä»¶å¯¹è±¡
   * @param fileName æ–‡ä»¶å
   * @returns æ–‡ä»¶å“ˆå¸Œ
   */
  const generateHashKey = async (
    options: { scene: UploadSceneEnum; enableDeduplication: boolean },
    fileObj: File,
    fileName: string
  ) => {
    let key: string

    if (options.enableDeduplication) {
      // ä½¿ç”¨æ–‡ä»¶å“ˆå¸Œä½œä¸ºæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†ï¼Œå®ç°å»é‡
      const fileHash = await calculateFileHash(fileObj)
      const fileSuffix = fileName.split('.').pop() || ''
      // è·å–å½“å‰ç™»å½•ç”¨æˆ·çš„account
      const account = userStore.userInfo.account
      key = `${options.scene}/${account}/${fileHash}.${fileSuffix}`
      console.log('ä½¿ç”¨æ–‡ä»¶å»é‡æ¨¡å¼ï¼Œæ–‡ä»¶å“ˆå¸Œ:', fileHash)
    } else {
      // ä½¿ç”¨æ—¶é—´æˆ³ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
      key = `${options.scene}/${Date.now()}_${fileName}`
    }
    return key
  }

  /**
   * ä¸Šä¼ æ–‡ä»¶åˆ°é»˜è®¤å­˜å‚¨ - æ”¯æŒåˆ†ç‰‡ä¸Šä¼ 
   * @param url ä¸Šä¼ é“¾æ¥
   * @param file æ–‡ä»¶
   */
  const uploadToDefault = async (url: string, file: File) => {
    isUploading.value = true

    try {
      if (file.size > CHUNK_THRESHOLD) {
        await uploadToDefaultWithChunks(url, file)
      } else {
        // å°†Fileå¯¹è±¡è½¬æ¢ä¸ºArrayBuffer
        const arrayBuffer = await file.arrayBuffer()

        const response = await fetch(url, {
          method: 'PUT',
          headers: {
            'Content-Type': file.type
          },
          body: arrayBuffer,
          duplex: 'half'
        } as RequestInit)

        isUploading.value = false

        if (response.ok) {
          trigger('success')
        } else {
          trigger('fail')
        }
      }
    } catch (error) {
      isUploading.value = false
      console.error('Upload failed:', error)
      trigger('fail')
    }
  }

  /**
   * åˆ†ç‰‡ä¸Šä¼ åˆ°é»˜è®¤å­˜å‚¨
   * @param url ä¸Šä¼ é“¾æ¥
   * @param file æ–‡ä»¶
   */
  const uploadToDefaultWithChunks = async (url: string, file: File) => {
    progress.value = 0
    const chunkSize = DEFAULT_CHUNK_SIZE
    const totalSize = file.size
    const totalChunks = Math.ceil(totalSize / chunkSize)

    console.log('å¼€å§‹é»˜è®¤å­˜å‚¨åˆ†ç‰‡ä¸Šä¼ :', {
      fileName: file.name,
      fileSize: totalSize,
      chunkSize,
      totalChunks
    })

    try {
      // åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ä¸Šä¼ ä¼šè¯ID
      const uploadId = `upload_${Date.now()}_${Math.random().toString(36).substring(2)}`

      for (let i = 0; i < totalChunks; i++) {
        const start = i * chunkSize
        const end = Math.min(start + chunkSize, totalSize)
        const chunk = file.slice(start, end)
        const chunkArrayBuffer = await chunk.arrayBuffer()

        // ä¸ºæ¯ä¸ªåˆ†ç‰‡æ·»åŠ å¿…è¦çš„å¤´ä¿¡æ¯
        const headers: Record<string, string> = {
          'Content-Type': 'application/octet-stream',
          'X-Chunk-Index': i.toString(),
          'X-Total-Chunks': totalChunks.toString(),
          'X-Upload-Id': uploadId,
          'X-File-Name': file.name,
          'X-File-Size': totalSize.toString()
        }

        // å¦‚æœæ˜¯æœ€åä¸€ä¸ªåˆ†ç‰‡ï¼Œæ·»åŠ å®Œæˆæ ‡è®°
        if (i === totalChunks - 1) {
          headers['X-Last-Chunk'] = 'true'
        }

        const response = await fetch(url, {
          method: 'PUT',
          headers,
          body: chunkArrayBuffer,
          duplex: 'half'
        } as RequestInit)

        if (!response.ok) {
          throw new Error(`åˆ†ç‰‡ ${i + 1}/${totalChunks} ä¸Šä¼ å¤±è´¥: ${response.statusText}`)
        }

        // æ›´æ–°è¿›åº¦
        progress.value = Math.floor(((i + 1) / totalChunks) * 100)
        trigger('progress') // è§¦å‘è¿›åº¦äº‹ä»¶

        console.log(`åˆ†ç‰‡ ${i + 1}/${totalChunks} ä¸Šä¼ æˆåŠŸ, è¿›åº¦: ${progress.value}%`)
      }

      isUploading.value = false
      progress.value = 100
      trigger('success')
    } catch (error) {
      isUploading.value = false
      console.error('é»˜è®¤å­˜å‚¨åˆ†ç‰‡ä¸Šä¼ å¤±è´¥:', error)
      throw error
    }
  }

  /**
   * ä¸Šä¼ æ–‡ä»¶åˆ°ä¸ƒç‰›äº‘
   * @param file æ–‡ä»¶
   * @param qiniuConfig ä¸ƒç‰›äº‘é…ç½®
   * @param enableDeduplication æ˜¯å¦å¯ç”¨æ–‡ä»¶å»é‡
   */
  const uploadToQiniu = async (
    file: File,
    scene: UploadSceneEnum,
    qiniuConfig: { token: string; domain: string; storagePrefix: string; region?: string },
    enableDeduplication: boolean = true
  ) => {
    isUploading.value = true
    progress.value = 0

    try {
      // åˆ›å»ºFormDataå¯¹è±¡
      const formData = new FormData()

      // ç”Ÿæˆæ–‡ä»¶å
      const key = await generateHashKey({ scene, enableDeduplication }, file, file.name)

      // æ·»åŠ ä¸ƒç‰›äº‘ä¸Šä¼ æ‰€éœ€å‚æ•°
      formData.append('token', qiniuConfig.token)
      formData.append('key', key)
      formData.append('file', file)

      // ä½¿ç”¨fetch APIè¿›è¡Œä¸Šä¼ 
      const response = await fetch(qiniuConfig.domain, {
        method: 'POST',
        body: formData
      })

      isUploading.value = false

      if (response.ok) {
        const result = await response.json()
        const downloadUrl = `${configStore.config.qiNiu.ossDomain}/${result.key || key}`
        trigger('success')
        return { downloadUrl, key }
      } else {
        trigger('fail')
        return { error: 'Upload failed' }
      }
    } catch (error) {
      isUploading.value = false
      console.error('Qiniu upload failed:', error)
      return { error: 'Upload failed' }
    }
  }

  /**
   * å°†æ–‡ä»¶åˆ†ç‰‡å¹¶ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘
   * @param file æ–‡ä»¶
   * @param qiniuConfig ä¸ƒç‰›äº‘é…ç½®
   * @param chunkSize åˆ†ç‰‡å¤§å°ï¼ˆå­—èŠ‚ï¼‰
   * @param inner æ˜¯å¦å†…éƒ¨è°ƒç”¨
   */
  const uploadToQiniuWithChunks = async (
    file: File,
    qiniuConfig: { token: string; domain: string; storagePrefix: string; region?: string },
    chunkSize: number = QINIU_CHUNK_SIZE,
    inner?: boolean
  ) => {
    isUploading.value = true
    progress.value = 0

    try {
      // ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
      const key = `${qiniuConfig.storagePrefix}/${Date.now()}_${file.name}`

      // è®¡ç®—åˆ†ç‰‡æ•°é‡
      const totalSize = file.size
      const totalChunks = Math.ceil(totalSize / chunkSize)

      // åˆ›å»ºè¿›åº¦è·Ÿè¸ªå¯¹è±¡
      const progressInfo: ChunkProgressInfo = {
        uploadedChunks: 0,
        totalChunks,
        currentChunkProgress: 0
      }

      console.log('å¼€å§‹ä¸ƒç‰›äº‘åˆ†ç‰‡ä¸Šä¼ :', {
        fileName: file.name,
        fileSize: totalSize,
        chunkSize,
        totalChunks,
        token: qiniuConfig.token.substring(0, 10) + '...',
        domain: qiniuConfig.domain
      })

      // ä½¿ç”¨ä¸ƒç‰›äº‘çš„åˆ†ç‰‡ä¸Šä¼ API v2 - åˆ›å»ºä¸Šä¼ å—
      const contexts: string[] = []

      for (let i = 0; i < totalChunks; i++) {
        const start = i * chunkSize
        const end = Math.min(start + chunkSize, totalSize)
        const chunkData = await file.slice(start, end).arrayBuffer()
        const currentChunkSize = end - start

        // åˆ›å»ºå—
        const blockResponse = await fetch(`${qiniuConfig.domain}/mkblk/${currentChunkSize}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/octet-stream',
            Authorization: `UpToken ${qiniuConfig.token}`
          },
          body: chunkData
        })

        if (!blockResponse.ok) {
          const errorText = await blockResponse.text()
          console.error(`ä¸Šä¼ åˆ†ç‰‡ ${i + 1}/${totalChunks} å¤±è´¥:`, {
            status: blockResponse.status,
            statusText: blockResponse.statusText,
            errorText
          })
          throw new Error(`ä¸Šä¼ åˆ†ç‰‡ ${i + 1}/${totalChunks} å¤±è´¥: ${blockResponse.statusText}`)
        }

        const blockResult = await blockResponse.json()
        contexts.push(blockResult.ctx)
        progressInfo.uploadedChunks++

        progress.value = Math.floor((progressInfo.uploadedChunks / progressInfo.totalChunks) * 100)

        console.log(`ä¸Šä¼ åˆ†ç‰‡ ${progressInfo.uploadedChunks}/${progressInfo.totalChunks} æˆåŠŸ:`, {
          ctx: blockResult.ctx.substring(0, 10) + '...',
          progress: progress.value + '%'
        })
      }

      // å®Œæˆä¸Šä¼  - åˆå¹¶æ‰€æœ‰å—
      const completeResponse = await fetch(`${qiniuConfig.domain}/mkfile/${totalSize}/key/${btoa(key)}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'text/plain',
          Authorization: `UpToken ${qiniuConfig.token}`
        },
        body: contexts.join(',')
      })

      if (!completeResponse.ok) {
        throw new Error(`å®Œæˆåˆ†ç‰‡ä¸Šä¼ å¤±è´¥: ${completeResponse.statusText}`)
      }

      const completeResult = await completeResponse.json()
      console.log('å®Œæˆåˆ†ç‰‡ä¸Šä¼ :', completeResult)

      isUploading.value = false
      progress.value = 100

      if (inner) return { key, domain: qiniuConfig.domain }

      const downloadUrl = `${qiniuConfig.domain}/${completeResult.key || key}`
      trigger('success')
      return { downloadUrl, key }
    } catch (error) {
      isUploading.value = false
      if (!inner) {
        trigger('fail')
      }
      console.error('ä¸ƒç‰›äº‘åˆ†ç‰‡ä¸Šä¼ å¤±è´¥:', error)
      return { error: 'Upload failed' }
    }
  }

  /**
   * è·å–å›¾ç‰‡å®½é«˜
   */
  const getImgWH = async (file: File) => {
    try {
      const result = await getImageDimensions(file, { includePreviewUrl: true })
      return {
        width: result.width,
        height: result.height,
        tempUrl: result.previewUrl!
      }
    } catch (error) {
      return { width: 0, height: 0, url: null }
    }
  }

  /**
   * è·å–éŸ³é¢‘æ—¶é•¿
   */
  const getAudioDuration = (file: File) => {
    return new Promise((resolve, reject) => {
      const audio = new Audio()
      const tempUrl = URL.createObjectURL(file)
      audio.src = tempUrl
      // è®¡ç®—éŸ³é¢‘çš„æ—¶é•¿
      const countAudioTime = async () => {
        while (isNaN(audio.duration) || audio.duration === Infinity) {
          // é˜²æ­¢æµè§ˆå™¨å¡æ­»
          await new Promise((resolve) => setTimeout(resolve, 100))
          // éšæœºè¿›åº¦æ¡ä½ç½®
          audio.currentTime = 100000 * Math.random()
        }
        // å–æ•´
        const second = Math.round(audio.duration || 0)
        resolve({ second, tempUrl })
      }
      countAudioTime()
      audio.onerror = function () {
        reject({ second: 0, tempUrl })
      }
    })
  }

  /**
   * è§£ææ–‡ä»¶
   * @param file æ–‡ä»¶
   * @param addParams å‚æ•°
   * @returns æ–‡ä»¶å¤§å°ã€æ–‡ä»¶ç±»å‹ã€æ–‡ä»¶åã€æ–‡ä»¶åç¼€...
   */
  const parseFile = async (file: File, addParams: Record<string, any> = {}) => {
    const { name, size, type } = file
    const suffix = name.split('.').pop()?.trim().toLowerCase() || ''
    const baseInfo = { name, size, type, suffix, ...addParams }

    // TODOï¼šè¿™é‡Œåº”è¯¥ä¸éœ€è¦è¿›è¡Œç±»å‹åˆ¤æ–­äº†ï¼Œå¯ä»¥ç›´æ¥è¿”å›baseInfo
    if (type.includes('image')) {
      const { width, height, tempUrl } = (await getImgWH(file)) as any
      return { ...baseInfo, width, height, tempUrl }
    }

    if (type.includes('audio')) {
      const { second, tempUrl } = (await getAudioDuration(file)) as any
      return { second, tempUrl, ...baseInfo }
    }
    // å¦‚æœæ˜¯è§†é¢‘
    if (type.includes('video')) {
      return { ...baseInfo }
    }

    return baseInfo
  }

  /**
   * ä¸Šä¼ æ–‡ä»¶
   * @param file æ–‡ä»¶
   * @param options ä¸Šä¼ é€‰é¡¹
   */
  const uploadFile = async (file: File, options?: UploadOptions) => {
    if (isUploading.value || !file) return

    // è®¾ç½®å½“å‰ä¸Šä¼ æ–¹å¼
    if (options?.provider) {
      currentProvider.value = options.provider
    }

    const info = await parseFile(file, options)

    // é™åˆ¶æ–‡ä»¶å¤§å°
    if (info.size > MAX_FILE_SIZE) {
      window.$message.error(`æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡ ${Max}MB`)
      return
    }

    // æ ¹æ®ä¸Šä¼ æ–¹å¼é€‰æ‹©ä¸åŒçš„ä¸Šä¼ é€»è¾‘
    if (currentProvider.value === UploadProviderEnum.QINIU) {
      try {
        // è·å–ä¸ƒç‰›äº‘token
        const qiniuConfig = await apis.getQiniuToken()
        fileInfo.value = { ...info }
        await onStart.trigger(fileInfo)

        // åˆ¤æ–­æ˜¯å¦ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ 
        console.log(`ğŸ“ uploadFile - æ–‡ä»¶å¤§å°æ£€æŸ¥: ${file.size} bytes, é˜ˆå€¼: ${CHUNK_THRESHOLD} bytes`)
        if (file.size > CHUNK_THRESHOLD) {
          console.log('âœ… uploadFile - ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ æ–¹å¼')
          const result = (await uploadToQiniuWithChunks(file, qiniuConfig, QINIU_CHUNK_SIZE)) as any
          if (result && result.downloadUrl) {
            fileInfo.value = { ...info, downloadUrl: result.downloadUrl }
          }
          return result
        } else {
          console.log('âœ… uploadFile - ä½¿ç”¨é»˜è®¤çš„æ™®é€šä¸Šä¼ æ–¹å¼')
          const result = await uploadToQiniu(
            file,
            options?.scene || UploadSceneEnum.CHAT,
            qiniuConfig,
            options?.enableDeduplication || true
          )
          if (result && result.downloadUrl) {
            fileInfo.value = { ...info, downloadUrl: result.downloadUrl }
          }
          return result
        }
      } catch (error) {
        console.error('è·å–ä¸ƒç‰›äº‘tokenå¤±è´¥:', error)
        await trigger('fail')
      }
    } else {
      // ä½¿ç”¨é»˜è®¤ä¸Šä¼ æ–¹å¼
      try {
        const scene = options?.scene || UploadSceneEnum.CHAT
        const { downloadUrl, uploadUrl } = await apis.getUploadUrl({ fileName: info.name, scene })

        if (uploadUrl && downloadUrl) {
          fileInfo.value = { ...info, downloadUrl }
          await onStart.trigger(fileInfo)
          await uploadToDefault(uploadUrl, file)
          return { downloadUrl }
        } else {
          await trigger('fail')
        }
      } catch (error) {
        console.error('è·å–ä¸Šä¼ é“¾æ¥å¤±è´¥:', error)
        await trigger('fail')
      }
    }
  }

  /**
   * è·å–ä¸Šä¼ å’Œä¸‹è½½URL
   * å¦‚æœæ˜¯é»˜è®¤ä¸Šä¼ æ–¹å¼ï¼Œè·å–ä¸Šä¼ å’Œä¸‹è½½URLï¼Œæ‰§è¡Œä¸Šä¼ 
   * å¦‚æœæ˜¯ä¸ƒç‰›äº‘ä¸Šä¼ æ–¹å¼ï¼Œè·å–ä¸ƒç‰›äº‘tokenï¼Œä¸æ‰§è¡Œä¸Šä¼ 
   * @param path æ–‡ä»¶è·¯å¾„
   * @param options ä¸Šä¼ é€‰é¡¹
   */
  const getUploadAndDownloadUrl = async (
    path: string,
    options?: UploadOptions
  ): Promise<{ uploadUrl: string; downloadUrl: string; config?: any }> => {
    // è®¾ç½®å½“å‰ä¸Šä¼ æ–¹å¼
    if (options?.provider) {
      currentProvider.value = options.provider
    }

    // æ ¹æ®ä¸Šä¼ æ–¹å¼é€‰æ‹©ä¸åŒçš„ä¸Šä¼ é€»è¾‘
    if (currentProvider.value === UploadProviderEnum.QINIU) {
      try {
        // è·å–ä¸ƒç‰›äº‘token
        const qiniuConfig = await apis.getQiniuToken()

        const config = {
          ...qiniuConfig,
          provider: options?.provider,
          scene: options?.scene
        }

        // å¯¹äºä¸ƒç‰›äº‘ï¼Œæˆ‘ä»¬ä¸éœ€è¦é¢„å…ˆè·å–ä¸Šä¼ URLï¼Œè€Œæ˜¯ç›´æ¥è¿”å›ä¸€ä¸ªæ ‡è®°
        return {
          uploadUrl: UploadProviderEnum.QINIU, // æ ‡è®°ä¸ºä¸ƒç‰›äº‘ä¸Šä¼ 
          downloadUrl: qiniuConfig.domain, // ä¸‹è½½URLä¼šåœ¨å®é™…ä¸Šä¼ åç”Ÿæˆ
          config: config
        }
      } catch (error) {
        throw new Error('è·å–ä¸ƒç‰›äº‘tokenå¤±è´¥ï¼Œè¯·é‡è¯•')
      }
    } else {
      // ä½¿ç”¨é»˜è®¤ä¸Šä¼ æ–¹å¼
      console.log('å¼€å§‹é»˜è®¤ä¸Šä¼ å›¾ç‰‡:', path)
      const fileName = extractFileName(path)
      if (!fileName) {
        throw new Error('æ–‡ä»¶è§£æå‡ºé”™')
      }

      try {
        const scene = options?.scene || UploadSceneEnum.CHAT
        const res = await apis.getUploadUrl({
          fileName: fileName,
          scene
        })

        console.log('è·å–ä¸Šä¼ é“¾æ¥æˆåŠŸ:', res)
        return res
      } catch (error) {
        throw new Error('è·å–ä¸Šä¼ é“¾æ¥å¤±è´¥ï¼Œè¯·é‡è¯•')
      }
    }
  }

  /**
   * æ‰§è¡Œå®é™…çš„æ–‡ä»¶ä¸Šä¼ 
   * @param path æ–‡ä»¶è·¯å¾„
   * @param uploadUrl ä¸Šä¼ URL
   * @param options ä¸Šä¼ é€‰é¡¹
   */
  const doUpload = async (path: string, uploadUrl: string, options?: any): Promise<{ qiniuUrl: string } | string> => {
    // å¦‚æœæ˜¯ä¸ƒç‰›äº‘ä¸Šä¼ 
    if (uploadUrl === UploadProviderEnum.QINIU && options) {
      // å¦‚æœæ²¡æœ‰æä¾›ä¸ƒç‰›äº‘é…ç½®ï¼Œå°è¯•è·å–
      if (!options.domain || !options.token) {
        try {
          console.log('è·å–ä¸ƒç‰›äº‘é…ç½®...')
          const qiniuConfig = await apis.getQiniuToken()
          options.domain = qiniuConfig.domain
          options.token = qiniuConfig.token
          options.storagePrefix = qiniuConfig.storagePrefix
          options.region = qiniuConfig.region
        } catch (error) {
          console.error('ä¸ƒç‰›äº‘ä¸Šä¼ é…ç½®ä¸å®Œæ•´ï¼Œç¼ºå°‘ domain æˆ– token', error)
        }
      }

      try {
        const file = await readFile(path, { baseDir: BaseDirectory.AppCache })
        console.log(`ğŸ“ è¯»å–æ–‡ä»¶: ${path}, å¤§å°: ${file.length} bytes`)

        // åˆ›å»ºFileå¯¹è±¡
        const fileName = extractFileName(path)
        const fileObj = new File([new Uint8Array(file)], fileName, {
          type: getFileType(fileName)
        })
        console.log(`ğŸ“¦ åˆ›å»ºFileå¯¹è±¡: ${fileName}, åŸå§‹å¤§å°: ${fileObj.size} bytes, æ•°ç»„å¤§å°: ${file.length} bytes`)

        isUploading.value = true
        progress.value = 0

        console.log('ä¸ƒç‰›äº‘ä¸Šä¼ å¼€å§‹:', {
          token: options.token,
          domain: options.domain,
          scene: options.scene,
          storagePrefix: options.storagePrefix,
          fileName,
          fileSize: file.length,
          enableDeduplication: options.enableDeduplication
        })

        // åˆ¤æ–­æ˜¯å¦ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ 
        console.log(`ğŸ“ æ–‡ä»¶å¤§å°æ£€æŸ¥: ${file.length} bytes, é˜ˆå€¼: ${CHUNK_THRESHOLD} bytes`)
        if (file.length > CHUNK_THRESHOLD) {
          console.log('âœ… ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ æ–¹å¼')

          // æ‰§è¡Œåˆ†ç‰‡ä¸Šä¼ 
          const chunkSize = QINIU_CHUNK_SIZE
          const totalSize = file.length
          const totalChunks = Math.ceil(totalSize / chunkSize)

          // åˆ›å»ºè¿›åº¦è·Ÿè¸ªå¯¹è±¡
          const progressInfo: ChunkProgressInfo = {
            uploadedChunks: 0,
            totalChunks,
            currentChunkProgress: 0
          }

          // ç”Ÿæˆæ–‡ä»¶åå’Œkey
          const key = await generateHashKey(
            { scene: options.scene, enableDeduplication: options.enableDeduplication },
            fileObj,
            fileName
          )

          console.log('å¼€å§‹ä¸ƒç‰›äº‘åˆ†ç‰‡ä¸Šä¼ :', {
            fileName,
            fileSize: totalSize,
            chunkSize,
            totalChunks,
            key
          })

          // ä½¿ç”¨ä¸ƒç‰›äº‘çš„åˆ†ç‰‡ä¸Šä¼ API v2 - åˆ›å»ºä¸Šä¼ å—
          const contexts: string[] = []

          for (let i = 0; i < totalChunks; i++) {
            const start = i * chunkSize
            const end = Math.min(start + chunkSize, totalSize)
            const chunkData = file.slice(start, end)
            const currentChunkSize = end - start

            // åˆ›å»ºå—
            const blockResponse = await fetch(`${options.domain}/mkblk/${currentChunkSize}`, {
              method: 'POST',
              headers: {
                'Content-Type': 'application/octet-stream',
                Authorization: `UpToken ${options.token}`
              },
              body: chunkData
            })

            if (!blockResponse.ok) {
              const errorText = await blockResponse.text()
              console.error(`ä¸Šä¼ åˆ†ç‰‡ ${i + 1}/${totalChunks} å¤±è´¥:`, {
                status: blockResponse.status,
                statusText: blockResponse.statusText,
                errorText
              })
              throw new Error(`ä¸Šä¼ åˆ†ç‰‡ ${i + 1}/${totalChunks} å¤±è´¥: ${blockResponse.statusText}`)
            }

            const blockResult = await blockResponse.json()
            contexts.push(blockResult.ctx)
            progressInfo.uploadedChunks++

            progress.value = Math.floor((progressInfo.uploadedChunks / progressInfo.totalChunks) * 100)
            console.log(`â¬†ï¸ åˆ†ç‰‡ä¸Šä¼ è§¦å‘è¿›åº¦äº‹ä»¶: ${progress.value}%`)
            trigger('progress') // è§¦å‘è¿›åº¦äº‹ä»¶

            console.log(`ä¸Šä¼ åˆ†ç‰‡ ${progressInfo.uploadedChunks}/${progressInfo.totalChunks} æˆåŠŸ:`, {
              ctx: blockResult.ctx.substring(0, 10) + '...',
              progress: progress.value + '%'
            })
          }

          // å®Œæˆä¸Šä¼  - åˆå¹¶æ‰€æœ‰å—
          const encodedKey = btoa(key)
          const completeResponse = await fetch(`${options.domain}/mkfile/${totalSize}/key/${encodedKey}`, {
            method: 'POST',
            headers: {
              'Content-Type': 'text/plain',
              Authorization: `UpToken ${options.token}`
            },
            body: contexts.join(',')
          })

          if (!completeResponse.ok) {
            const errorText = await completeResponse.text()
            console.error('å®Œæˆåˆ†ç‰‡ä¸Šä¼ å¤±è´¥:', {
              status: completeResponse.status,
              statusText: completeResponse.statusText,
              errorText
            })
            throw new Error(`å®Œæˆåˆ†ç‰‡ä¸Šä¼ å¤±è´¥: ${completeResponse.statusText}`)
          }

          const completeResult = await completeResponse.json()
          console.log('å®Œæˆåˆ†ç‰‡ä¸Šä¼ :', completeResult)
          console.log('åŸå§‹key:', key)
          console.log('å“åº”key:', completeResult.key)

          isUploading.value = false
          progress.value = 100

          const qiniuUrl = `${configStore.config.qiNiu.ossDomain}/${completeResult.key || key}`
          trigger('success')
          return qiniuUrl
        } else {
          console.log('âœ… uploadFile - ä½¿ç”¨ä¸ƒç‰›æ™®é€šä¸Šä¼ æ–¹å¼')
          // ä½¿ç”¨æ™®é€šä¸Šä¼ æ–¹å¼
          // åˆ›å»ºFormDataå¯¹è±¡
          const formData = new FormData()

          // ç”Ÿæˆæ–‡ä»¶åå’Œkey
          const key = await generateHashKey(
            { scene: options.scene, enableDeduplication: options.enableDeduplication },
            fileObj,
            fileName
          )

          formData.append('token', options.token)
          formData.append('key', key)
          formData.append('file', fileObj)

          // ä½¿ç”¨fetch APIè¿›è¡Œä¸Šä¼ 
          const response = await fetch(options.domain, {
            headers: {
              Host: options.storagePrefix
            },
            method: 'POST',
            body: formData
          } as RequestInit)

          isUploading.value = false
          progress.value = 100

          console.log('ä¸ƒç‰›äº‘ä¸Šä¼ å“åº”:', {
            status: response.status,
            statusText: response.statusText
          })

          if (response.ok) {
            const result = await response.json()
            console.log('ä¸ƒç‰›äº‘ä¸Šä¼ æˆåŠŸ:', result)
            const qiniuUrl = `${configStore.config.qiNiu.ossDomain}/${result.key}`
            trigger('success')
            return qiniuUrl
          } else {
            const errorText = await response.text()
            console.error('ä¸ƒç‰›äº‘ä¸Šä¼ å¤±è´¥:', {
              status: response.status,
              statusText: response.statusText,
              errorText
            })
            trigger('fail')
            throw new Error(`ä¸Šä¼ å¤±è´¥: ${response.statusText}`)
          }
        }
      } catch (error) {
        isUploading.value = false
        trigger('fail')
        console.error('ä¸ƒç‰›äº‘ä¸Šä¼ å¤±è´¥:', error)
        throw new Error('æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œè¯·é‡è¯•')
      }
    } else {
      // ä½¿ç”¨é»˜è®¤ä¸Šä¼ æ–¹å¼
      console.log('æ‰§è¡Œæ–‡ä»¶ä¸Šä¼ :', path)
      try {
        const file = await readFile(path, { baseDir: BaseDirectory.AppCache })

        // æ·»åŠ æ–‡ä»¶å¤§å°æ£€æŸ¥
        if (file.length > MAX_FILE_SIZE) {
          throw new Error(`æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡${Max}MB`)
        }

        isUploading.value = true
        progress.value = 0

        if (file.length > CHUNK_THRESHOLD) {
          // è½¬æ¢fileçš„ç±»å‹
          // TODOï¼šæœ¬åœ°ä¸Šä¼ è¿˜éœ€è¦æµ‹è¯•
          const fileObj = new File([file], __filename, { type: 'application/octet-stream' })
          await uploadToDefaultWithChunks(uploadUrl, fileObj)
        } else {
          const response = await fetch(uploadUrl, {
            headers: { 'Content-Type': 'application/octet-stream' },
            method: 'PUT',
            body: file,
            duplex: 'half'
          } as RequestInit)

          isUploading.value = false
          progress.value = 100

          if (!response.ok) {
            trigger('fail')
            throw new Error(`ä¸Šä¼ å¤±è´¥: ${response.statusText}`)
          }

          console.log('æ–‡ä»¶ä¸Šä¼ æˆåŠŸ')
          trigger('success')
        }

        // è¿”å›ä¸‹è½½URL
        return options?.downloadUrl
      } catch (error) {
        isUploading.value = false
        trigger('fail')
        console.error('æ–‡ä»¶ä¸Šä¼ å¤±è´¥:', error)
        throw new Error('æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œè¯·é‡è¯•')
      }
    }
  }

  return {
    fileInfo,
    isUploading,
    progress,
    onStart: onStart.on,
    onChange,
    uploadFile,
    parseFile,
    uploadToQiniu,
    getUploadAndDownloadUrl,
    doUpload,
    UploadProviderEnum
  }
}
